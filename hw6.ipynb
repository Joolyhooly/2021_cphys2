{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1686d4",
   "metadata": {},
   "source": [
    "# Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a43f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f535a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d439b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959aefba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4565fdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbb1049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29706c0ce80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[2], cmap = 'pink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eed8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.flatten(train_data.data,start_dim=1)/255).float()\n",
    "y = train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b43f37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f274281",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = (torch.flatten(test_data.data,start_dim=1)/255).float()\n",
    "y_2 = test_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6c35f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145e3152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input, hidden layer 1,2, output = 784, 256,256, 10 \n",
    "din, dh_1, dh_2, dout = 784, 256, 256, 10\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(din,dh_1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dh_1,dh_2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dh_2, dout), # pytorch의 CrossEntropyLoss 함수에 softmax가 포함되어 있으므로 Softmax 넣지 않았음\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d24a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f27b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.3047053813934326 tensor(0.0842)\n",
      "1 2.013629674911499 tensor(0.4906)\n",
      "2 1.3718464374542236 tensor(0.5534)\n",
      "3 1.5873003005981445 tensor(0.5778)\n",
      "4 1.661365032196045 tensor(0.5317)\n",
      "5 0.9266183972358704 tensor(0.6805)\n",
      "6 0.8025016784667969 tensor(0.7311)\n",
      "7 0.8323615789413452 tensor(0.6918)\n",
      "8 0.7631441354751587 tensor(0.7362)\n",
      "9 0.6252925395965576 tensor(0.8204)\n",
      "10 0.5283607244491577 tensor(0.8453)\n",
      "11 0.4907297194004059 tensor(0.8416)\n",
      "12 0.4720950126647949 tensor(0.8457)\n",
      "13 0.43878868222236633 tensor(0.8625)\n",
      "14 0.3949172794818878 tensor(0.8808)\n",
      "15 0.3697201609611511 tensor(0.8880)\n",
      "16 0.34909936785697937 tensor(0.8946)\n",
      "17 0.3343629837036133 tensor(0.9026)\n",
      "18 0.3284759223461151 tensor(0.9050)\n",
      "19 0.31071263551712036 tensor(0.9099)\n",
      "20 0.2878279983997345 tensor(0.9151)\n",
      "21 0.2672589421272278 tensor(0.9211)\n",
      "22 0.2533905506134033 tensor(0.9253)\n",
      "23 0.24842330813407898 tensor(0.9262)\n",
      "24 0.24037960171699524 tensor(0.9282)\n",
      "25 0.22525285184383392 tensor(0.9324)\n",
      "26 0.21068549156188965 tensor(0.9372)\n",
      "27 0.20157937705516815 tensor(0.9393)\n",
      "28 0.19745400547981262 tensor(0.9406)\n",
      "29 0.192512646317482 tensor(0.9422)\n",
      "30 0.184038445353508 tensor(0.9445)\n",
      "31 0.17506669461727142 tensor(0.9467)\n",
      "32 0.16802625358104706 tensor(0.9492)\n",
      "33 0.16264471411705017 tensor(0.9504)\n",
      "34 0.15768538415431976 tensor(0.9517)\n",
      "35 0.1532360464334488 tensor(0.9534)\n",
      "36 0.1481134593486786 tensor(0.9554)\n",
      "37 0.1428215205669403 tensor(0.9571)\n",
      "38 0.13786567747592926 tensor(0.9582)\n",
      "39 0.13359510898590088 tensor(0.9589)\n",
      "40 0.1298854947090149 tensor(0.9600)\n",
      "41 0.12571480870246887 tensor(0.9615)\n",
      "42 0.12137100100517273 tensor(0.9629)\n",
      "43 0.1175517588853836 tensor(0.9644)\n",
      "44 0.11420533806085587 tensor(0.9658)\n",
      "45 0.11073044687509537 tensor(0.9663)\n",
      "46 0.10733474045991898 tensor(0.9674)\n",
      "47 0.1041150689125061 tensor(0.9683)\n",
      "48 0.10099341720342636 tensor(0.9695)\n",
      "49 0.09803683310747147 tensor(0.9703)\n",
      "50 0.09509377926588058 tensor(0.9711)\n",
      "51 0.09228777885437012 tensor(0.9718)\n",
      "52 0.08954116702079773 tensor(0.9728)\n",
      "53 0.08695241808891296 tensor(0.9736)\n",
      "54 0.08453880250453949 tensor(0.9746)\n",
      "55 0.08200037479400635 tensor(0.9754)\n",
      "56 0.07945261150598526 tensor(0.9759)\n",
      "57 0.07718595117330551 tensor(0.9768)\n",
      "58 0.0750407874584198 tensor(0.9773)\n",
      "59 0.07285753637552261 tensor(0.9780)\n",
      "60 0.07064858078956604 tensor(0.9787)\n",
      "61 0.06859654933214188 tensor(0.9792)\n",
      "62 0.066558837890625 tensor(0.9799)\n",
      "63 0.06452234089374542 tensor(0.9805)\n",
      "64 0.0625527948141098 tensor(0.9814)\n",
      "65 0.060691311955451965 tensor(0.9820)\n",
      "66 0.058886174112558365 tensor(0.9828)\n",
      "67 0.05709852650761604 tensor(0.9833)\n",
      "68 0.055362533777952194 tensor(0.9839)\n",
      "69 0.05366469547152519 tensor(0.9845)\n",
      "70 0.05200954154133797 tensor(0.9850)\n",
      "71 0.050412651151418686 tensor(0.9857)\n",
      "72 0.04880587384104729 tensor(0.9860)\n",
      "73 0.04723825678229332 tensor(0.9865)\n",
      "74 0.04572947323322296 tensor(0.9870)\n",
      "75 0.0442688874900341 tensor(0.9876)\n",
      "76 0.042857006192207336 tensor(0.9878)\n",
      "77 0.041541051119565964 tensor(0.9884)\n",
      "78 0.04036860167980194 tensor(0.9887)\n",
      "79 0.039143599569797516 tensor(0.9891)\n",
      "80 0.03771400824189186 tensor(0.9898)\n",
      "81 0.03627495467662811 tensor(0.9902)\n",
      "82 0.03509518504142761 tensor(0.9906)\n",
      "83 0.03415006399154663 tensor(0.9908)\n",
      "84 0.033027105033397675 tensor(0.9911)\n",
      "85 0.031735483556985855 tensor(0.9915)\n",
      "86 0.03064241260290146 tensor(0.9919)\n",
      "87 0.0297071635723114 tensor(0.9922)\n",
      "88 0.028738850727677345 tensor(0.9926)\n",
      "89 0.027660300955176353 tensor(0.9931)\n",
      "90 0.02660772018134594 tensor(0.9934)\n",
      "91 0.025743206962943077 tensor(0.9936)\n",
      "92 0.024883074685931206 tensor(0.9939)\n",
      "93 0.023992231115698814 tensor(0.9941)\n",
      "94 0.023088928312063217 tensor(0.9945)\n",
      "95 0.022236282005906105 tensor(0.9948)\n",
      "96 0.02147744596004486 tensor(0.9950)\n",
      "97 0.020721860229969025 tensor(0.9952)\n",
      "98 0.019937997683882713 tensor(0.9954)\n",
      "99 0.019191894680261612 tensor(0.9956)\n",
      "100 0.01847160793840885 tensor(0.9959)\n",
      "101 0.017811812460422516 tensor(0.9961)\n",
      "102 0.017159217968583107 tensor(0.9962)\n",
      "103 0.016493994742631912 tensor(0.9965)\n",
      "104 0.015860319137573242 tensor(0.9967)\n",
      "105 0.015274735167622566 tensor(0.9969)\n",
      "106 0.01470140926539898 tensor(0.9970)\n",
      "107 0.014147607609629631 tensor(0.9972)\n",
      "108 0.013609461486339569 tensor(0.9974)\n",
      "109 0.01307767815887928 tensor(0.9975)\n",
      "110 0.01258714310824871 tensor(0.9977)\n",
      "111 0.012119123712182045 tensor(0.9978)\n",
      "112 0.011667503975331783 tensor(0.9980)\n",
      "113 0.011210031807422638 tensor(0.9981)\n",
      "114 0.010771885514259338 tensor(0.9983)\n",
      "115 0.010357346385717392 tensor(0.9984)\n",
      "116 0.009976023808121681 tensor(0.9984)\n",
      "117 0.009605609811842442 tensor(0.9986)\n",
      "118 0.009218361228704453 tensor(0.9986)\n",
      "119 0.008855350315570831 tensor(0.9987)\n",
      "120 0.008525613695383072 tensor(0.9989)\n",
      "121 0.00820170808583498 tensor(0.9990)\n",
      "122 0.007879042066633701 tensor(0.9991)\n",
      "123 0.007567663677036762 tensor(0.9992)\n",
      "124 0.0072754970751702785 tensor(0.9992)\n",
      "125 0.007003007922321558 tensor(0.9993)\n",
      "126 0.0067317429929971695 tensor(0.9994)\n",
      "127 0.00646722037345171 tensor(0.9994)\n",
      "128 0.006218405440449715 tensor(0.9995)\n",
      "129 0.005986258387565613 tensor(0.9995)\n",
      "130 0.005754611920565367 tensor(0.9995)\n",
      "131 0.005535950884222984 tensor(0.9996)\n",
      "132 0.005326760932803154 tensor(0.9996)\n",
      "133 0.005126366391777992 tensor(0.9997)\n",
      "134 0.004931795410811901 tensor(0.9997)\n",
      "135 0.0047448319382965565 tensor(0.9997)\n",
      "136 0.0045690047554671764 tensor(0.9997)\n",
      "137 0.004402343183755875 tensor(0.9998)\n",
      "138 0.004235432017594576 tensor(0.9998)\n",
      "139 0.004082076251506805 tensor(0.9998)\n",
      "140 0.003931250423192978 tensor(0.9998)\n",
      "141 0.0037851817905902863 tensor(0.9998)\n",
      "142 0.0036479083355516195 tensor(0.9998)\n",
      "143 0.003513355739414692 tensor(0.9998)\n",
      "144 0.003382641589269042 tensor(0.9998)\n",
      "145 0.00325974402949214 tensor(0.9998)\n",
      "146 0.003141100285574794 tensor(0.9998)\n",
      "147 0.0030270663555711508 tensor(0.9998)\n",
      "148 0.002918817335739732 tensor(0.9998)\n",
      "149 0.002813944360241294 tensor(0.9998)\n",
      "150 0.0027125810738652945 tensor(0.9999)\n",
      "151 0.002616747049614787 tensor(0.9999)\n",
      "152 0.002523877192288637 tensor(0.9999)\n",
      "153 0.002434676280245185 tensor(0.9999)\n",
      "154 0.0023512239567935467 tensor(0.9999)\n",
      "155 0.002269731368869543 tensor(0.9999)\n",
      "156 0.002192271640524268 tensor(0.9999)\n",
      "157 0.002120389835909009 tensor(0.9999)\n",
      "158 0.0020486433058977127 tensor(1.0000)\n",
      "159 0.0019814709667116404 tensor(1.0000)\n",
      "160 0.001917975372634828 tensor(1.0000)\n",
      "161 0.0018571498803794384 tensor(1.0000)\n",
      "162 0.001799381454475224 tensor(1.0000)\n",
      "163 0.0017440629890188575 tensor(1.0000)\n",
      "164 0.0016924722585827112 tensor(1.)\n",
      "165 0.001642477116547525 tensor(1.)\n",
      "166 0.0015947764040902257 tensor(1.)\n",
      "167 0.0015489169163629413 tensor(1.)\n",
      "168 0.0015053959796205163 tensor(1.)\n",
      "169 0.0014638046268373728 tensor(1.)\n",
      "170 0.0014240099117159843 tensor(1.)\n",
      "171 0.001386042800731957 tensor(1.)\n",
      "172 0.0013492116704583168 tensor(1.)\n",
      "173 0.0013140493538230658 tensor(1.)\n",
      "174 0.0012799962423741817 tensor(1.)\n",
      "175 0.0012476647971197963 tensor(1.)\n",
      "176 0.0012164736399427056 tensor(1.)\n",
      "177 0.0011865844717249274 tensor(1.)\n",
      "178 0.0011575956596061587 tensor(1.)\n",
      "179 0.0011297967284917831 tensor(1.)\n",
      "180 0.0011030579917132854 tensor(1.)\n",
      "181 0.0010775483679026365 tensor(1.)\n",
      "182 0.001053060288541019 tensor(1.)\n",
      "183 0.00102936290204525 tensor(1.)\n",
      "184 0.0010066765826195478 tensor(1.)\n",
      "185 0.0009845340391620994 tensor(1.)\n",
      "186 0.0009633901645429432 tensor(1.)\n",
      "187 0.0009428681223653257 tensor(1.)\n",
      "188 0.0009231567964889109 tensor(1.)\n",
      "189 0.0009040217264555395 tensor(1.)\n",
      "190 0.000885587593074888 tensor(1.)\n",
      "191 0.0008678187732584774 tensor(1.)\n",
      "192 0.0008505143923684955 tensor(1.)\n",
      "193 0.0008338380721397698 tensor(1.)\n",
      "194 0.0008176474366337061 tensor(1.)\n",
      "195 0.0008020143141038716 tensor(1.)\n",
      "196 0.0007867667591199279 tensor(1.)\n",
      "197 0.0007720465073361993 tensor(1.)\n",
      "198 0.000757688598241657 tensor(1.)\n",
      "199 0.0007438051979988813 tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred,y)\n",
    "    optimizer.zero_grad() # zero_grad(): 미분값 초기화 \n",
    "    loss.backward() # backpropagation\n",
    "    optimizer.step() # update weights and biases\n",
    "   \n",
    "    prediction = y_pred.max(1)[1]\n",
    "    corrects = (prediction == y)\n",
    "    accuracy = corrects.sum().float() / float( y.size(0) )\n",
    "    print(epoch, loss.item(), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89ffc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "with torch.no_grad():\n",
    "  y_pred2 = model(x_2)\n",
    "  loss2 = criterion(y_pred2, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e8c5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    " prediction2 = y_pred2.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7adad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9743)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects2 = (prediction2 == y_2)\n",
    "accuracy2 = corrects2.sum().float() / float( y_2.size(0) )\n",
    "accuracy2 #TEST DATA 정확도 = accuracy2 = 0.9743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c47dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
